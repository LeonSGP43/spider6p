import fs from 'fs';
import path from 'path';
import { config } from './config.js';
import {
  TikTokSpider,
  InstagramSpider,
  TwitterSpider,
  YouTubeSpider,
  LinkedInSpider,
  RedditSpider
} from './src/platforms/index.js';
import { requestCounter } from './src/utils/http.js';

const spiders = {
  tiktok: new TikTokSpider(),
  instagram: new InstagramSpider(),
  twitter: new TwitterSpider(),
  youtube: new YouTubeSpider(),
  linkedin: new LinkedInSpider(),
  reddit: new RedditSpider()
};

async function crawlAll() {
  console.log('='.repeat(60));
  console.log('Spider6P - Multi-Platform Social Media Crawler');
  console.log(`Tags: ${config.spider.tags.join(', ')}`);
  console.log(`Limit per tag: ${config.spider.limit}`);
  console.log('='.repeat(60));

  const enabledPlatforms = Object.entries(config.platforms)
    .filter(([_, cfg]) => cfg.enabled)
    .map(([key]) => key);

  console.log(`\nEnabled platforms: ${enabledPlatforms.join(', ')}\n`);

  // å¹¶å‘çˆ¬å–æ‰€æœ‰å¹³å°
  const crawlPromises = enabledPlatforms.map(async (platform) => {
    const spider = spiders[platform];
    if (!spider) {
      console.error(`[Error] Spider not found for platform: ${platform}`);
      return { platform, success: false, error: 'Spider not found' };
    }
    return spider.crawl(config.spider.tags, config.spider.limit);
  });

  const results = await Promise.allSettled(crawlPromises);

  // æ±‡æ€»ç»“æžœ
  const summary = {
    timestamp: new Date().toISOString(),
    tags: config.spider.tags,
    platforms: {}
  };

  results.forEach((result, index) => {
    const platform = enabledPlatforms[index];
    if (result.status === 'fulfilled') {
      summary.platforms[platform] = result.value;
    } else {
      summary.platforms[platform] = {
        platform,
        success: false,
        error: result.reason?.message || 'Unknown error'
      };
    }
  });

  // æ‰“å°æ±‡æ€»
  console.log('\n' + '='.repeat(60));
  console.log('CRAWL SUMMARY');
  console.log('='.repeat(60));

  for (const [platform, data] of Object.entries(summary.platforms)) {
    const status = data.success ? 'âœ“' : 'âœ—';
    const counts = data.data 
      ? Object.entries(data.data).map(([tag, items]) => `#${tag}: ${items.length}`).join(', ')
      : 'N/A';
    console.log(`[${status}] ${platform.toUpperCase()}: ${counts}`);
  }

  // æ‰“å° API è°ƒç”¨ç»Ÿè®¡
  const apiStats = requestCounter.getSummary();
  console.log('\n' + '-'.repeat(60));
  console.log('API CALL STATISTICS');
  console.log('-'.repeat(60));
  console.log(`ðŸ“Š Total API Calls: ${apiStats.total}`);
  console.log(`   âœ“ Success: ${apiStats.success}`);
  console.log(`   âœ— Failed: ${apiStats.failed}`);
  console.log('-'.repeat(60));

  // ä¿å­˜æ•°æ®åˆ° JSON æ–‡ä»¶
  await saveResults(summary);

  return summary;
}

// ä¿å­˜çˆ¬å–ç»“æžœåˆ° JSON æ–‡ä»¶
async function saveResults(summary) {
  const outputDir = 'output';
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  const timestamp = new Date().toISOString().replace(/[:.]/g, '-').slice(0, 19);
  
  // ä¿å­˜å®Œæ•´æ±‡æ€»
  const summaryFile = path.join(outputDir, `crawl_${timestamp}.json`);
  fs.writeFileSync(summaryFile, JSON.stringify(summary, null, 2));
  console.log(`\nðŸ“ Saved: ${summaryFile}`);

  // æŒ‰å¹³å°åˆ†åˆ«ä¿å­˜
  for (const [platform, data] of Object.entries(summary.platforms)) {
    if (data.success && data.data) {
      const platformFile = path.join(outputDir, `${platform}_${timestamp}.json`);
      fs.writeFileSync(platformFile, JSON.stringify(data, null, 2));
      console.log(`ðŸ“ Saved: ${platformFile}`);
    }
  }
}

// å¯¼å‡ºä¾›å¤–éƒ¨ä½¿ç”¨
export { crawlAll, spiders, config };

// ç›´æŽ¥è¿è¡Œ
if (process.argv[1].endsWith('index.js')) {
  crawlAll()
    .then(summary => {
      console.log('\nâœ“ Crawl completed');
      console.log(`Output: ${JSON.stringify(summary, null, 2).slice(0, 500)}...`);
    })
    .catch(err => {
      console.error('Crawl failed:', err);
      process.exit(1);
    });
}
